# CCKS2025 Competation Repo

## 任务简介

比赛任务是 NLP 中的经典任务：文本分类。具体来说，模型需要判断文本是由大模型生成的还是人类撰写的。

## 思路

目前的思路是利用预训练模型 Bert 在给定数据集上进行微调。由于训练集和测试集分布不太相同，因此我们需要尽可能的保证模型的泛化能力，避免过拟合。也就是尽可能捕捉数据集的有代表性的特征。

为了实现这个目标，我们考虑从两个角度入手：

- SimCES 对比学习框架；
- 传统机器学习的特征提取。

### SimCES 框架

类似于 SimCLR，SimCES 框架可以实现**自监督**学习，具体来说，算法利用模型的 `Dropout` 随机性，对一段文本执行两次独立的嵌入，在得到的向量上计算 infoNCE 损失，最大化负样本对之间的差异，最小化正样本对之间的差异。

### 传统机器学习特征提取

通过提取文本的各种特征，来丰富学习模型的学习材料，考虑：

- TF/IDF
- 文本丰富度

等。（这部分还需要完善）

### DeTeCtive 框架

DeTeCtive 是一种用于检测 AI 生成文本的新型框架，其核心思想是通过**多级对比学习**（Multi-Level Contrastive Learning）和**多任务辅助学习**（Multi-task Auxiliary Learning）来区分不同写作风格，而非传统的二分类（人类 vs. AI）。参考：[DeTeCtive: Detecting AI-generated Text via Multi-Level Contrastive Learning](https://arxiv.org/abs/2410.20964)。

#### 框架概述
DeTeCtive 的设计目标是解决现有检测方法在面对新模型（如大语言模型 LLMs）和分布外（OOD）数据时性能下降的问题。其核心思路是将检测任务转化为**区分不同作者的写作风格**（包括不同 LLM 系列、同一公司模型、人类写作等），从而学习更细粒度的特征。框架分为两个阶段：
- **训练阶段**：通过多级对比学习优化模型，使其能够区分不同层次的文本关系。
- **推理阶段**：结合密集信息检索（Dense Information Retrieval）和 KNN 分类，利用预编码数据库进行高效检测。

#### 核心技术组件

##### (1) 多级对比学习（Multi-Level Contrastive Learning）
多级对比学习的目标是通过设计多层次的对比损失函数，区分不同级别的文本关系（如人类 vs. AI、同一模型系列 vs. 不同公司模型等）。其核心思想是：
- **多层次相似性建模**：将文本的分布划分为四个层级：
  - **P1**：特定 LLM 生成的文本。
  - **P2**：同一公司开发的 LLM 生成的文本。
  - **P3**：任意 LLM 生成的文本。
  - **P4**：人类写作的文本。
- **对比损失设计**：通过约束不同层级文本的相似性，使模型学习到细粒度特征。例如，公式 (1) 要求：

```math
  \mathbb{E}_{x \sim P_i, y \sim P_j}[\text{Sim}(\Phi(x),\Phi(y))] > \mathbb{E}_{x \sim P_i, y \sim P_{j+1}}[\text{Sim}(\Phi(x),\Phi(y))], \quad \forall 1 \leq i \leq j < 4
```

  其中 $\Phi(\cdot)$ 是编码函数，Sim 是相似度度量（如余弦相似度）。

- **多级对比损失函数**：基于 SimCLR 框架，定义正样本和负样本集合，并计算对比损失。正样本集合包含满足条件的多级相似文本，负样本集合包含不相似文本。最终损失函数为：

```math
  L_{\text{mcl}} = \sum_{i=1}^N x_i \cdot (\delta \cdot L_{qi,1}) + (1 - x_i) \cdot (\alpha \cdot L_{qi,2} + \beta \cdot L_{qi,3} + \gamma \cdot L_{qi,4})
```

  其中 $\delta, \alpha, \beta, \gamma$ 是权重系数，用于平衡不同层级的关系 。

##### (2) 多任务辅助学习（Multi-task Auxiliary Learning）
在对比学习的基础上，引入二分类任务（判断文本是否为 AI 生成）作为辅助任务，进一步提升模型泛化能力。具体步骤：
- **分类任务**：在编码器输出层添加一个 MLP 分类器，执行二分类（人类 vs. AI）。
- **交叉熵损失**：定义分类损失函数：

````math
  L_{\text{ce}} = -\frac{1}{N} \sum_{i=1}^N x_i \cdot \log(p_i) + (1 - x_i) \cdot \log(1 - p_i)
```

  其中 $p_i$ 是第 $i$ 个样本被预测为人类写作的概率。
- **联合优化**：总损失函数为对比损失和分类损失的加权和：

```math
  L_{\text{all}} = L_{\text{mcl}} + L_{\text{ce}}
```

##### (3) 密集信息检索与 KNN 分类
推理阶段采用以下流程：
1. **预编码数据库**：将训练数据的特征向量预先编码并存储到数据库中。
2. **特征匹配**：对输入文本进行编码后，计算其与数据库中所有特征向量的余弦相似度。
3. **KNN 分类**：通过 K 近邻（KNN）算法确定输入文本的类别（人类或 AI 生成）。

#### 3. 训练无关的增量适应（TFIA）
TFIA（Training-Free Incremental Adaptation）是 DeTeCtive 的关键创新之一，旨在无需重新训练的情况下适应新模型或新领域数据。具体步骤：
1. **增量编码**：将新数据（如未见过的模型生成文本）通过已训练的编码器编码为特征向量。
2. **数据库更新**：将新特征向量添加到预编码数据库中，形成扩展数据库。
3. **推理增强**：使用扩展数据库进行 KNN 分类，显著提升 OOD 数据的检测性能（例如，在未见领域数据上平均召回率提升 7.03%）。

## 代码架构

本仓库文件结构如下：
```
.
├── data                # 数据文件夹
│   ├── test.jsonl      # 测试集
│   └── train.jsonl     # 训练集
├── finetune.py         # 在分类任务上微调预训练模型
├── modules.py          # 类模块（模型定义）
├── predict.py          # 对测试集进行预测并生成提交文件
├── pretrain.py         # 利用 SimCES 微调预训练模型
├── README.md
├── utils.py            # 工具函数
└── xgb.py              # 调用提升树分类器
```
如果不利用 SimCES 架构，可修改 `fintune.py` 中的模型 `model_path` 和 `tokenizer_path` 为 huggingface 中的预训练模型路径模型路径如 `bert-base-uncased`。则会直接在分类任务上对 bert 进行微调。其他代码文件调用预训练模型方法同理。

## 实验日志

- [6月3日] 从目前的实验结果来看，SimCES 框架效果并不好，直接微调 Bert 模型有过最好结果 83 分，另外使用 xgb 分类器效果也一般，下一步考虑使用微调 Bert + 集成学习分类器。
- [6月5日] 目前来看，Bert + 集成学习是一条可行的路子，将 Bert + xgb 的结果提升到了 75 分，特征方面，改进的 `get_features` 能达到 77 分。
- [6月6日] 直接调用 DeTeCtive 模型对 test 进行推理，F1 分数达到 80，下面考虑针对本次比赛数据集训练新的模型权重。
